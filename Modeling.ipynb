{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ----here it will only consider those words/tokens for any sentense which appeared in top 10000 most appeared word in whole vocubolary\n",
    "## ----it mean maximum distinct tokens we can have is 10000.\n",
    "max_feature = 10000 \n",
    "(x_train, y_train),(x_test, y_test) = imdb.load_data(num_words= max_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   19,  178,   32],\n",
       "       [   0,    0,    0, ...,   16,  145,   95],\n",
       "       [   0,    0,    0, ...,    7,  129,  113],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    4, 3586,    2],\n",
       "       [   0,    0,    0, ...,   12,    9,   23],\n",
       "       [   0,    0,    0, ...,  204,  131,    9]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   19,  178,   32],\n",
       "       [   0,    0,    0, ...,   16,  145,   95],\n",
       "       [   0,    0,    0, ...,    7,  129,  113],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    4, 3586,    2],\n",
       "       [   0,    0,    0, ...,   12,    9,   23],\n",
       "       [   0,    0,    0, ...,  204,  131,    9]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "max_len = 500 ## here it will help us to filterour those sample reviews where feature is less than 500\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen= max_len, padding= 'pre')\n",
    "x_test = sequence.pad_sequences(x_test, maxlen= max_len, padding= 'pre')\n",
    "x_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 500, 128)          1280000   \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,313,025\n",
      "Trainable params: 1,313,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "## input_dim: here we define the numbers of all tokens we have\n",
    "## input_legth:  here we define input length of each review\n",
    "\n",
    "model.add(Embedding(input_dim=max_feature, output_dim= 128, input_length= max_len))\n",
    "model.add(SimpleRNN(128, activation= 'relu'))\n",
    "model.add(Dense(1, activation= 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer= 'adam', loss= 'binary_crossentropy', metrics= 'mae')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1205s 602ms/step - loss: 1355991875584.0000 - mae: 0.4462 - val_loss: 0.5922 - val_mae: 0.4238\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "earlystopping = EarlyStopping(monitor= 'val_loss', patience= 5, restore_best_weights= True)\n",
    "history = model.fit(x_train, y_train, epochs= 1, verbose= 1, batch_size= 10, callbacks=[earlystopping] , validation_split= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(sample):\n",
    "    example_review =sample\n",
    "    l_word = example_review.lower().split()\n",
    "    val_word = [dic.get(word, 2)+ 3 for word in l_word]\n",
    "    padded_seq = sequence.pad_sequences([val_word], maxlen= 500)\n",
    "    return padded_seq\n",
    "\n",
    "def prediction(seq):\n",
    "    result= model.predict(seq)[0][0]\n",
    "\n",
    "    if result > 0.5:\n",
    "        print(\"Review is positive with {:.2f}\".format(result*100),\"%\")\n",
    "    else:\n",
    "        print(\"Review is negative with {:.2f}\".format(result*100),\"%\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review is negative with 35.98 %\n"
     ]
    }
   ],
   "source": [
    "example_review = \"This movie was fantastic! The acting was great and the plot was thrilling.\"\n",
    "\n",
    "padded_seq = preprocessing(example_review)\n",
    "prediction(padded_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Embedding_RNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
